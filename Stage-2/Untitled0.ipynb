{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST"
      ],
      "metadata": {
        "id": "aDCBYNpHwVHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REGRESSÃO"
      ],
      "metadata": {
        "id": "4zuSP0WuwYNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJRstRRTwSIU"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
        "model = xgb.XGBRegressor(n_estimators=7)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Acessando as árvores ajustadas\n",
        "booster = model.get_booster()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.feature_names, len(data.feature_names)"
      ],
      "metadata": {
        "id": "wsZ-PPfKweWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "booster.save_model('model.json')"
      ],
      "metadata": {
        "id": "stdh0ajIwfEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trees = booster.get_dump(with_stats=False)  # Inclui estatísticas adicionais\n",
        "len(trees)"
      ],
      "metadata": {
        "id": "BUEn7JHkbirH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Exibir as árvores"
      ],
      "metadata": {
        "id": "UOkLkqdkwiQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo as árvores\n",
        "for i, tree in enumerate(trees):\n",
        "    print(f\"Tree {i}:\")\n",
        "    print(tree)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "soLUwT-Rwlxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trees[0])"
      ],
      "metadata": {
        "id": "XGWFyoBuwnkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = data.feature_names\n",
        "\n",
        "# exibe as árvores com nomes de features\n",
        "trees = booster.get_dump(with_stats=True)\n",
        "\n",
        "# f para substituir f0, f1... pelos nomes das features\n",
        "def replace_feature_names(tree, feature_names):\n",
        "    for i, feature in enumerate(feature_names):\n",
        "        tree = tree.replace(f\"f{i}\", feature)\n",
        "    return tree\n",
        "\n",
        "for i, tree in enumerate(trees):\n",
        "    print(f\"Tree {i}:\")\n",
        "    print(replace_feature_names(tree, feature_names))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    break\n"
      ],
      "metadata": {
        "id": "QjZ0rvg4won7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "booster.trees_to_dataframe()"
      ],
      "metadata": {
        "id": "_keiAv1fwqZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFICAÇÃO"
      ],
      "metadata": {
        "id": "Mj_DL47twvWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#model = xgb.XGBClassifier(n_estimators=7, max_depth=3, learning_rate=0.1, use_label_encoder=False, eval_metric='mlogloss')\n",
        "model = xgb.XGBClassifier(n_estimators=7)\n",
        "model.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "jFq6pwe-wwGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Exibir plot das trees"
      ],
      "metadata": {
        "id": "SKWg0i33w3V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_tree(model, num_trees=0)"
      ],
      "metadata": {
        "id": "yiaQ2iMVw67q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(trees)):\n",
        "  xgb.plot_tree(model, num_trees=i)"
      ],
      "metadata": {
        "id": "tsTJ7F74w77d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Pegando dados das Árvores"
      ],
      "metadata": {
        "id": "cpDjolXzw-Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acessando as árvores ajustadas\n",
        "booster = model.get_booster()\n",
        "\n",
        "# Obtendo as árvores em formato de texto\n",
        "trees = booster.get_dump(with_stats=False)"
      ],
      "metadata": {
        "id": "x-skfc9jxCGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    ** get_dump(fmap='', with_stats=False, dump_format='text')\n",
        "    Returns the model dump as a list of strings. Unlike save_model(), the output format is\n",
        "    primarily used for visualization or interpretation, hence it’s more human readable but cannot\n",
        "    be loaded back to XGBoost.\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "            fmap (str | PathLike) – Name of the file containing feature map names.\n",
        "\n",
        "            with_stats (bool) – Controls whether the split statistics are output.\n",
        "\n",
        "            dump_format (str) – Format of model dump. Can be ‘text’, ‘json’ or ‘dot’.\n",
        "\n",
        "    Return type:\n",
        "        List[str]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "trees = booster.get_dump(with_stats=False, dump_format='json')\n",
        "print(trees[0])"
      ],
      "metadata": {
        "id": "EYqEODjhxDox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trees = booster.get_dump(with_stats=False, dump_format='text')\n",
        "print(trees[0])"
      ],
      "metadata": {
        "id": "x14gjxabxPLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trees = booster.get_dump(with_stats=False)\n",
        "print(trees[0])"
      ],
      "metadata": {
        "id": "iNHNrot2xTmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Quantidade de Árvores"
      ],
      "metadata": {
        "id": "-W1yP8HGxWbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(trees)\n",
        "print(len(trees))\n",
        "\n",
        "print()\n",
        "classes = model.classes_\n",
        "print(classes, len(classes))\n",
        "\n",
        "feature_names = data.feature_names\n",
        "print(feature_names, len(feature_names))\n",
        "\n",
        "print()\n",
        "print('Quantidade de Árvores: ', len(classes) * len(trees)/(len(classes)))"
      ],
      "metadata": {
        "id": "jbMyyIQCxYZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Exibindo árvores"
      ],
      "metadata": {
        "id": "WOm_rdAhxbgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo as árvores com os índices das features\n",
        "for i, tree in enumerate(trees):\n",
        "    print(f\"Tree {i}:\")\n",
        "    print(tree)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "u8PxXm0nxd_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo as árvores com os nomes das features (igual ao que fizemos na regressão)\n",
        "feature_names = data.feature_names  # Nomes das features do dataset Iris\n",
        "\n",
        "\n",
        "def replace_feature_names(tree, feature_names):\n",
        "    for i, feature in enumerate(feature_names):\n",
        "        tree = tree.replace(f\"f{i}\", feature)\n",
        "    return tree\n",
        "\n",
        "for i, tree in enumerate(trees):\n",
        "    print(f\"Tree {i}:\")\n",
        "    print(replace_feature_names(tree, feature_names))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "3U2snES6xfrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 mY method"
      ],
      "metadata": {
        "id": "4MBKOYfexiHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_tree(tree_str):\n",
        "    tree = []\n",
        "    lines = tree_str.split('\\n')  # Dividindo a árvore linha por linha\n",
        "\n",
        "    for line in lines:\n",
        "        # Removendo indentação e espaços\n",
        "        line = line.strip()\n",
        "\n",
        "        # Verificando se é um nó ou uma folha\n",
        "        if 'leaf' in line:\n",
        "            # Extraindo o número do nó e o valor da folha\n",
        "            node_num = re.search(r'(\\d+):leaf=([-\\d.]+)', line)\n",
        "            if node_num:\n",
        "                tree.append({'node': int(node_num.group(1)), 'leaf': float(node_num.group(2))})\n",
        "        else:\n",
        "            # Extraindo informações de nós\n",
        "            node_info = re.search(r'(\\d+):\\[f(\\d+)<([-\\d.]+)\\] yes=(\\d+),no=(\\d+),missing=(\\d+)', line)\n",
        "            if node_info:\n",
        "                tree.append({\n",
        "                    'node': int(node_info.group(1)),\n",
        "                    'feature': int(node_info.group(2)),\n",
        "                    'threshold': float(node_info.group(3)),\n",
        "                    'yes': int(node_info.group(4)),\n",
        "                    'no': int(node_info.group(5)),\n",
        "                    'missing': int(node_info.group(6))\n",
        "                })\n",
        "    return tree\n",
        "\n",
        "# Exemplo de uso\n",
        "i = 1\n",
        "tree_0 = trees[i]\n",
        "parsed_tree = parse_tree(tree_0)\n",
        "print(\"Fomated \", parsed_tree)\n",
        "print(\"Orig \", trees[i])\n"
      ],
      "metadata": {
        "id": "oWRFHmsfxmOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKLEARN"
      ],
      "metadata": {
        "id": "cbljt1I9xnJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_hastie_10_2\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "X, y = make_hastie_10_2(random_state=0)\n",
        "X_train, X_test = X[:2000], X[2000:]\n",
        "y_train, y_test = y[:2000], y[2000:]\n",
        "\n",
        "\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "                                max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "6Q4hF8OTZReO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Mostrando estimators_"
      ],
      "metadata": {
        "id": "8MlBe3tWxv6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.estimators_)"
      ],
      "metadata": {
        "id": "QGZcPCxfZSuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "for i, tree in enumerate(clf.estimators_):\n",
        "    print(f\"Tree {i}\")\n",
        "    tree_model = tree[0]\n",
        "    tree_rules = export_text(tree_model)\n",
        "    print(tree_rules)\n"
      ],
      "metadata": {
        "id": "HY5m0gQUx0-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}